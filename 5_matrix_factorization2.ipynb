{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create m x n matrix for Y\n",
    "Y_train = np.loadtxt('./data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('./data/test.txt').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 (Adding Bias Term a and b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_bias_U(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * Ui - Vj * (Yij - mu - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_V(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * Vj - Ui * (Yij - mu - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_a(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * ai - (Yij - mu - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_b(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * bj - (Yij - mu - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def bias_err(U, V, Y, a, b, mu, reg=0.0):    \n",
    "    err = 0\n",
    "    for x in range(Y.shape[0]):\n",
    "        i = Y[x][0] - 1\n",
    "        j = Y[x][1] - 1\n",
    "        \n",
    "        err += pow(Y[x][2] - (np.dot(U[i,:], V[j,:]) + a[i] + b[j]), 2)    \n",
    "    return 1 / Y.shape[0] * ((reg * (np.linalg.norm(U)**2 + np.linalg.norm(V)**2 \n",
    "                    + np.linalg.norm(a)**2 + np.linalg.norm(b)**2) + err) / 2) \n",
    "\n",
    "def train_bias_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    U = np.random.uniform(-0.5, 0.5, size=(M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, size=(N, K))\n",
    "    a = np.random.uniform(-0.5, 0.5, size=(M, ))\n",
    "    b = np.random.uniform(-0.5, 0.5, size=(N, ))\n",
    "    \n",
    "    mu = np.average(Y[:,2])\n",
    "    loss = []\n",
    "    loss.append(bias_err(U, V, Y, a, b, mu, reg))\n",
    "    \n",
    "    for epoch in range(max_epochs): \n",
    "        index = np.random.permutation(Y.shape[0])\n",
    "        for idx in index:\n",
    "            i = Y[idx][0] - 1\n",
    "            j = Y[idx][1] - 1\n",
    "            U[i,:] -= eta * grad_bias_U(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            V[j,:] -= eta * grad_bias_V(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            a[i] -= eta * grad_bias_a(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            b[j] -= eta * grad_bias_b(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "        \n",
    "        err = bias_err(U, V, Y, a, b, mu, reg)\n",
    "        loss.append(err)\n",
    "        if (abs(loss[-1] - loss[-2]) / abs(loss[1] - loss[0]) < eps):\n",
    "            print(epoch)\n",
    "            break\n",
    "    \n",
    "    err = bias_err(U, V, Y, a, b, mu)\n",
    "    return (U, V, err, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 943 users x 1682 movies \n",
    "mu = np.average(Y_test[:,2])\n",
    "# Use to compute Ein and Eout using k=20\n",
    "U_bias, V_bias, E_in_bias, a, b = train_bias_model(M, N, k, eta, reg, Y_train)\n",
    "E_out_bias = bias_err(U, V, Y_test, a, b, mu)\n",
    "\n",
    "print(\"Training error is: \" + str(E_in_bias))\n",
    "print(\"Test error is: \" + str(E_out_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(np.transpose(U_bias), np.tranpose(V_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 (Using scikit-surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(pd.DataFrame(np.concatenate((Y_train, Y_test))), reader)\n",
    "\n",
    "algo = SVD(n_factors = 20, biased=True)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.1)\n",
    "algo.fit(trainset)\n",
    "# User factors (u)\n",
    "u = algo.pu\n",
    "# Item factors (v)\n",
    "v = algo.qi\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
