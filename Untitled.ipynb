{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T11:54:44.096082Z",
     "start_time": "2020-02-27T11:54:44.072077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrix Factorization with Bias\n",
    "import numpy as np\n",
    "import random\n",
    "def grad_U(Ui, Yij, Vj, reg, eta, a, b):\n",
    "    return eta * (np.dot(reg, Ui) - (np.dot(Vj, ((Yij) - np.dot(Ui, Vj) - a - b ))))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta, a, b):\n",
    "    return eta * (np.dot(reg, Vj) - (np.dot(Ui, ((Yij) - np.dot(Ui, Vj) - a - b ))))\n",
    "\n",
    "\n",
    "def grad_A(Vj, Yij, Ui, reg, eta, a, b):\n",
    "    return -eta * ((Yij) - np.dot(Ui, Vj) - a - b  - (reg * a))\n",
    "    \n",
    "def grad_B(Vj, Yij, Ui, reg, eta, a, b):\n",
    "    return -eta * (((Yij) - np.dot(Ui, Vj) - a - b ) - (reg * b))\n",
    "    \n",
    "def get_err(U, V, Y, A, B, reg=0.0):\n",
    "    err = 0.0\n",
    "    for (i,j,Yij) in Y:\n",
    "        err += .5 * (((Yij) - (np.dot(U[i-1], V[j-1]) + A[i-1] + B[j-1])) ** 2)\n",
    "    return err / len(Y)\n",
    "\n",
    "    \n",
    "# Perform the (Yij - mean) part of the optimation function by offsetting each term by average.\n",
    "def center(train, test):\n",
    "    avg = np.mean(train[:,2])\n",
    "    train[:,2] = train[:,2 ] - avg\n",
    "    test[:,2] = test[:, 2] - avg\n",
    "    \n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "  \n",
    "    itr = 0\n",
    "    U = np.random.uniform(-0.5, 0.5, (M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, (N, K))\n",
    "    # Bias terms A, B\n",
    "    A = np.random.uniform(-0.5, 0.5, (M))\n",
    "    B = np.random.uniform(-0.5, 0.5, (N))\n",
    "    # get initial loss\n",
    "    ind = list(range(len(Y)))\n",
    "    shuffled = np.random.permutation(ind)\n",
    "    curr_loss = get_err(U, V, Y, A, B)\n",
    "    for k in range(len(Y)):\n",
    "        ind = shuffled[k]\n",
    "        i, j, Yij = Y[ind]\n",
    "        \n",
    "        # update U, V, A, B\n",
    "        u = grad_U(U[i-1], Yij, V[j-1], reg, eta, A[i-1], B[j-1])\n",
    "        v = grad_V(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "        a = grad_A(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "        b = grad_B(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "        U[i-1] = U[i-1] - u \n",
    "        V[j-1] = V[j-1] - v\n",
    "        A[i-1] = A[i-1] - a\n",
    "        B[j-1] = B[j-1] - b\n",
    "    \n",
    "    \n",
    "        \n",
    "    next_loss = get_err(U, V, Y, A, B)\n",
    "    init = curr_loss - next_loss\n",
    "    curr_delta = init\n",
    "    curr_loss = next_loss\n",
    "    \n",
    "    while itr < max_epochs and (curr_delta / init) > eps:\n",
    "        ind = list(range(len(Y)))\n",
    "        shuffled = np.random.permutation(ind)\n",
    "        for k in range(len(Y)):\n",
    "            ind = shuffled[k]\n",
    "            ii, jj, Yij = Y[ind]\n",
    "            i = int(ii)\n",
    "            j = int(jj)\n",
    "            # update U, V, A, B\n",
    "            u = grad_U(U[i-1], Yij, V[j-1], reg, eta, A[i-1], B[j-1])\n",
    "            v = grad_V(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "            a = grad_A(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "            b = grad_B(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "            U[i-1] = U[i-1] - u \n",
    "            V[j-1] = V[j-1] - v\n",
    "            A[i-1] = A[i-1] - a\n",
    "            B[j-1] = B[j-1] - b\n",
    "        next_loss = get_err(U,V,Y, A,B)\n",
    "        \n",
    "        curr_delta = curr_loss - next_loss\n",
    "        curr_loss = next_loss\n",
    "        itr += 1\n",
    "        \n",
    "    print(curr_loss, itr)\n",
    "    return U, V, curr_loss, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-27T12:17:06.548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find optimal lambda and stopping criteria\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)\n",
    "center(Y_train, Y_test)\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "K = 20\n",
    "eps = [.0001, 0.001, 0.01]\n",
    "\n",
    "regs = [0, 10**-4, 10**-2, 10**-1, 1]\n",
    "eta = 0.03 # learning rate\n",
    "E_ins = []\n",
    "E_outs = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "for reg in regs:\n",
    "    E_ins_for_lambda = []\n",
    "    E_outs_for_lambda = []\n",
    "    \n",
    "    for ep in eps:\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s, eps = %s\"%(M, N, K, eta, reg, ep))\n",
    "        U,V, e_in, A, B = train_model(M, N, K, eta, reg, Y_train, eps=ep)\n",
    "        E_ins_for_lambda.append(e_in)\n",
    "        eout = get_err(U, V, Y_test, A, B)\n",
    "        E_outs_for_lambda.append(eout)\n",
    "\n",
    "    E_ins.append(E_ins_for_lambda)\n",
    "    E_outs.append(E_outs_for_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
