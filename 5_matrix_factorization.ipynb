{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 (Modifying Code from Homework 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create m x n matrix for Y\n",
    "Y_train = np.loadtxt('./data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('./data/test.txt').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes an input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return reg * Ui - Vj * (Yij - np.dot(Ui, Vj))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes an input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return reg * Vj - Ui * (Yij - np.dot(Ui, Vj))\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes an input of a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    err = 0\n",
    "    for x in range(Y.shape[0]):\n",
    "        i = Y[x][0] - 1\n",
    "        j = Y[x][1] - 1\n",
    "        \n",
    "        err += pow(Y[x][2] - np.dot(U[i,:], V[j,:]), 2)    \n",
    "    return 1 / Y.shape[0] * ((reg * (np.linalg.norm(U)**2 + np.linalg.norm(V)**2) + err) / 2) \n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    U = np.random.uniform(-0.5, 0.5, size=(M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, size=(N, K))\n",
    "    loss = []\n",
    "    loss.append(get_err(U, V, Y, reg))\n",
    "    \n",
    "    for epoch in range(max_epochs): \n",
    "        index = np.random.permutation(Y.shape[0])\n",
    "        for idx in index:\n",
    "            i = Y[idx][0] - 1\n",
    "            j = Y[idx][1] - 1\n",
    "            U[i,:] -= eta * grad_U(U[i,:], Y[idx][2], V[j,:], reg, eta)\n",
    "            V[j,:] -= eta * grad_V(V[j,:], Y[idx][2], U[i,:], reg, eta)\n",
    "        \n",
    "        err = get_err(U, V, Y, reg)\n",
    "        loss.append(err)\n",
    "        if (abs(loss[-1] - loss[-2]) / abs(loss[1] - loss[0]) < eps):\n",
    "            break\n",
    "    \n",
    "    err = get_err(U, V, Y)\n",
    "    return (U, V, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with  943  users,  1682  movies.\n",
      "Training error is: 0.2494398706178021\n",
      "Test error is: 0.6733794601112535\n"
     ]
    }
   ],
   "source": [
    "# Create 943 users x 1682 movies \n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "\n",
    "k = 20\n",
    "\n",
    "reg = 0.0\n",
    "eta = 0.03 # learning rate\n",
    "\n",
    "# Use to compute Ein and Eout using k=20\n",
    "U, V, E_in = train_model(M, N, k, eta, reg, Y_train)\n",
    "E_out = get_err(U, V, Y_test)\n",
    "\n",
    "print(\"Training error is: \" + str(E_in))\n",
    "print(\"Test error is: \" + str(E_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 943)\n",
      "(2, 1682)\n"
     ]
    }
   ],
   "source": [
    "# Visualize and interpret results\n",
    "\n",
    "def visualize(U, V):\n",
    "    # The variable V is currently V^T\n",
    "    A, sigma, B = np.linalg.svd(V)\n",
    "\n",
    "    U_tilde = np.matmul(np.transpose(A[:,:2]), U)\n",
    "    V_tilde = np.matmul(np.transpose(A[:,:2]), V)\n",
    "\n",
    "    print(U_tilde.shape)\n",
    "    print(V_tilde.shape)\n",
    "    \n",
    "visualize(np.transpose(U), np.transpose(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 (Adding Bias Term a and b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_bias_U(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * Ui - Vj * (Yij - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_V(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * Vj - Ui * (Yij - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_a(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * ai - (Yij - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def grad_bias_b(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    return reg * bj - (Yij - np.dot(Ui, Vj) - ai - bj)\n",
    "\n",
    "def bias_err(U, V, Y, a, b, reg=0.0):\n",
    "    mu = np.average(Y)\n",
    "    \n",
    "    err = 0\n",
    "    for x in range(Y.shape[0]):\n",
    "        i = Y[x][0] - 1\n",
    "        j = Y[x][1] - 1\n",
    "        \n",
    "        err += pow(Y[x][2] - (np.dot(U[i,:], V[j,:]) + a[i] + b[j]), 2)    \n",
    "    return 1 / Y.shape[0] * ((reg * (np.linalg.norm(U)**2 + np.linalg.norm(V)**2 \n",
    "                    + np.linalg.norm(a)**2 + np.linalg.norm(b)**2) + err) / 2) \n",
    "\n",
    "def train_bias_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    U = np.random.uniform(-0.5, 0.5, size=(M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, size=(N, K))\n",
    "    a = np.random.uniform(-0.5, 0.5, size=(M, ))\n",
    "    b = np.random.uniform(-0.5, 0.5, size=(N, ))\n",
    "    \n",
    "    loss = []\n",
    "    loss.append(bias_err(U, V, Y, a, b, reg))\n",
    "    \n",
    "    mu = np.average(Y)\n",
    "    \n",
    "    for epoch in range(max_epochs): \n",
    "        index = np.random.permutation(Y.shape[0])\n",
    "        for idx in index:\n",
    "            i = Y[idx][0] - 1\n",
    "            j = Y[idx][1] - 1\n",
    "            U[i,:] -= eta * grad_bias_U(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            V[j,:] -= eta * grad_bias_V(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            a[i] -= eta * grad_bias_a(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "            b[j] -= eta * grad_bias_b(U[i,:], Y[idx][2], V[j,:], reg, eta, a[i], b[j], mu)\n",
    "        \n",
    "        err = bias_err(U, V, Y, a, b, reg)\n",
    "        loss.append(err)\n",
    "        if (abs(loss[-1] - loss[-2]) / abs(loss[1] - loss[0]) < eps):\n",
    "            break\n",
    "    \n",
    "    err = bias_err(U, V, Y, a, b)\n",
    "    return (U, V, err, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error is: 0.18380830212340524\n",
      "Test error is: 6.636491628376683\n"
     ]
    }
   ],
   "source": [
    "# Create 943 users x 1682 movies \n",
    "\n",
    "# Use to compute Ein and Eout using k=20\n",
    "U_bias, V_bias, E_in_bias, a, b = train_bias_model(M, N, k, eta, reg, Y_train)\n",
    "E_out_bias = bias_err(U, V, Y_test, a, b)\n",
    "\n",
    "print(\"Training error is: \" + str(E_in_bias))\n",
    "print(\"Test error is: \" + str(E_out_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(np.transpose(U_bias), np.tranpose(V_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 (Using scikit-surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-fc087e2747a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(pd.DataFrame(Y_train))\n",
    "predictions = algo.test(pd.DataFrame(Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
